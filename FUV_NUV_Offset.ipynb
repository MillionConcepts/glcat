{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e7e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from pyarrow import parquet \n",
    "import numpy as np\n",
    "import sys \n",
    "sys.path.append('/home/bekah/gPhoton2')\n",
    "from gPhoton.pipeline import execute_pipeline\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5bf6892",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_eclipse = 2505\n",
    "high_eclipse = 2507\n",
    "metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','>',low_eclipse),('eclipse','<',high_eclipse),\n",
    "                                           ('fuv_temp','>',0),\n",
    "                                          ('legs','==',0)]).to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88da484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eclipse</th>\n",
       "      <th>obstype</th>\n",
       "      <th>legs</th>\n",
       "      <th>ra_max</th>\n",
       "      <th>ra_min</th>\n",
       "      <th>dec_max</th>\n",
       "      <th>dec_min</th>\n",
       "      <th>fuv_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2506</td>\n",
       "      <td>MIS</td>\n",
       "      <td>0</td>\n",
       "      <td>32.934511</td>\n",
       "      <td>32.907482</td>\n",
       "      <td>14.282081</td>\n",
       "      <td>14.256885</td>\n",
       "      <td>29.924175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eclipse obstype  legs     ra_max     ra_min    dec_max    dec_min  \\\n",
       "0     2506     MIS     0  32.934511  32.907482  14.282081  14.256885   \n",
       "\n",
       "    fuv_temp  \n",
       "0  29.924175  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd28033",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_eclipse = 2505\n",
    "high_eclipse = 2507\n",
    "metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','>',low_eclipse),('eclipse','<',high_eclipse),\n",
    "                                           ('fuv_temp','>',0),\n",
    "                                          ('legs','==',0)]).to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d1644c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting timer\n",
      "eclipse 23456 FUV  -- MIS; 0 leg(s)\n",
      "downloading raw6file\n",
      "Processing eclipse 23456\n",
      "28.7778329060574\n",
      "Offsetting FUV image for eclipse 23456 at 28.7778329060574 degrees.\n",
      "fuvtemp: 28.7778329060574\n",
      "Setting FUV offsets to x=-0.12211, y=0.22794350369115263\n",
      "fodx_coef_0: -0.12211, fody_coef_0: 0.14803\n",
      "xoffset: -0.12211, yoffset: 0.22794350369115263\n",
      "trange= ( 874361241.995 , 874362946.995 )                   \n",
      "RA AVG: 323.48945087374165, DEC AVG: -2.066535934111889, ROLL AVG: 23.639969174886176\n",
      "Loading raw6 file...                                        \n",
      "4035551 events\n",
      "Unpacking raw6 data...                                      \n",
      "stim_coef0, stim_coef1 = -380625.36080072116, 0.0004411392059765214\n",
      "[8.74361652e+08 8.74361652e+08 8.74361652e+08 ... 8.74362085e+08\n",
      " 8.74362085e+08 8.74362085e+08][8.74362085e+08 8.74362085e+08 8.74362085e+08 ... 8.74362519e+08\n",
      " 8.74362519e+08 8.74362519e+08][8.74361242e+08 8.74361242e+08 8.74361242e+08 ... 8.74361652e+08\n",
      " 8.74361652e+08 8.74361652e+08]\n",
      "\n",
      "\n",
      "t len: 1000000t len: 1000000t len: 1000000\n",
      "\n",
      "\n",
      "[8.74362519e+08 8.74362519e+08 8.74362519e+08 ... 8.74362942e+08\n",
      " 8.74362942e+08 8.74362942e+08]\n",
      "t len: 1000000\n",
      "<class 'numpy.ndarray'>tortion correction...                \n",
      "[     1      2      3 ... 999997 999998 999999]\n",
      "<class 'numpy.ndarray'>\n",
      "[     0      1      2 ... 999996 999997 999998]x shift\n",
      "\n",
      "[-0.12211    -0.25876546  0.17975962 ... -0.12211    -0.12211\n",
      "  0.17028889]\n",
      "<class 'numpy.ndarray'>\n",
      "[     0      1      2 ... 999997 999998 999999]\n",
      "<class 'numpy.ndarray'>\n",
      "[     0      1      2 ... 999997 999998 999999]\n",
      "x shift\n",
      "x shift[-0.3816833  -0.13453902  0.02742087 ... -0.39143613 -0.25756798\n",
      " -0.12211   ]\n",
      "\n",
      "[-0.02894851  0.38303534 -0.03889811 ...  0.18358735  0.00435038\n",
      " -0.42195584]\n",
      "x shift\n",
      "[ 0.03533318 -0.18876729 -0.41563989 ...  0.30774453 -0.12211\n",
      "  0.20583641]\n",
      "xi leng: 1000000\n",
      "xi leng: 1000000ither correction...                         \n",
      "2/ 5: Interpolating aspect_data solutions...mes...                                                                      \n",
      "xi leng: 1000000oton times to aspect_data times...          \n",
      "[8.74362942e+08 8.74362942e+08 8.74362942e+08 ... 8.74362947e+08\n",
      " 8.74362947e+08 8.74362947e+08]\n",
      "t len: 12557\n",
      "<class 'numpy.ndarray'>tortion correction...                \n",
      "[    0     1     2 ... 12554 12555 12556]\n",
      "x shift\n",
      "[-0.26977712 -0.12211    -0.29115898 ... -0.11189131 -0.89220609\n",
      " -0.18581267]\n",
      "xi leng: 12557\n",
      "writing table to /media/bekah/BekahA/eclipses/e23456/e23456-fd-0.parquet\n",
      "                                                            \n",
      "Runtime statistics:\n",
      " runtime\t\t=\t4.151017904281616 sec. = (0.06918363173802694 min.)\n",
      "\tprocessed\t=\t4012557 of 4035551 events.\n",
      "\t\tWARNING: MISSING EVENTS! \n",
      "rate\t\t=\t972183.4723568606 photons/sec.\n",
      "\n",
      "21.14 elapsed seconds, restarting timer\n",
      "processing leg 1 of 1\n",
      "making images from /media/bekah/BekahA/eclipses/e23456/e23456-fd-0.parquet\n",
      "indexing data and making WCS solution\n",
      "image size: (3077, 3078)\n",
      "making full-depth image\n",
      "1.5 elapsed seconds, restarting timer\n",
      "entering sourcefinder 0.43\n",
      "Extracting extended and point sources.\n",
      "generated masked images 0.46\n",
      "1678.1945102357995 s exposure time\n",
      "Masking for extended sources.\n",
      "entering masking 0.46\n",
      "Running DAO for extended source ID.\n",
      "DAO 1\n",
      "dao finder 1 (1) 0.46\n",
      "dao finder 1 (2) 0.46\n",
      "dao finder 1 (3) 0.48\n",
      "DAO 2\n",
      "dao finder 2 (1) 0.48\n",
      "dao finder 2 (2) 0.48\n",
      "dao finder 2 (3) 0.48\n",
      "Found 77 peaks with DAO.\n",
      "get_extended (1) 0.48\n",
      "77\n",
      "get_extended (2) 0.48\n",
      "get_extended (3) 0.51\n",
      "get_extended (4) 0.51\n",
      "exiting masking 0.51\n",
      "entering segmentation 0.51\n",
      "Estimating background and threshold.\n",
      "entering estimation 0.51\n",
      "estimating background 0.51\n",
      "init background2d 0.62\n",
      "subtracted background 0.69\n",
      "deleted background 0.62\n",
      "calc background rms 0.69\n",
      "estimating threshold 0.51\n",
      "Calculating source threshold.\n",
      "convolved image 0.54\n",
      "Segmenting and deblending point sources.\n",
      "segmented 0.62\n",
      "post garbage collection 0.58\n",
      "exiting segmentation 0.67\n",
      "Checking for extended source overlap with point sources.\n",
      "check points 0.67\n",
      "Located 3987 sources\n",
      "saving segment map and extended source mask to files\n",
      "1\n",
      "saving extended source catalogue\n",
      "18.18 elapsed seconds, restarting timer\n",
      "length of positions: 3987\n",
      "length of source table: 3987\n",
      "length of apertures: 3987\n",
      "Performing aperture photometry on primary image.\n",
      "Performing aperture photometry on flag maps.\n",
      "Performing aperture photometry on edge maps.\n",
      "3987 world length\n",
      "0.39 elapsed seconds, restarting timer\n",
      "writing source table to /media/bekah/BekahA/eclipses/e23456/e23456-fd-full-0-photom-12_8.csv\n",
      "0.08 elapsed seconds, restarting timer\n",
      "writing full-depth image to /media/bekah/BekahA/eclipses/e23456/e23456-fd-full-0-rice.fits\n",
      "writing cnt map\n",
      "writing flag map\n",
      "writing edge map\n",
      "0.48 elapsed seconds, restarting timer\n",
      "41.78 seconds for execution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'return code: successful'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " execute_pipeline(23456,\n",
    "                        \"FUV\",\n",
    "                        depth=None,\n",
    "                        threads=4,\n",
    "                        verbose=10,\n",
    "                        local_root=f\"/media/bekah/BekahA/eclipses\",\n",
    "                        recreate=False,\n",
    "                        aperture_sizes=[12.8],\n",
    "                        write={\"movie\": False, \"image\": True},\n",
    "                        compression=\"rice\",\n",
    "                        lil=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bda663",
   "metadata": {},
   "outputs": [],
   "source": [
    "eclipse_list = [922, 1910, 2117, 2188, 2313, 2344, 2372, 2461, 2477,\n",
    "              2492, 2506, 2564, 2618]\n",
    "def make_eclipses(): \n",
    "    bands = [\"NUV\",\"FUV\"]\n",
    "    for eclipse in eclipse_list: \n",
    "        #eclipse = str(eclipse).zfill(5)\n",
    "        print(eclipse)\n",
    "        for band in bands: \n",
    "            try:\n",
    "                 execute_pipeline(\n",
    "                        eclipse,\n",
    "                        band,\n",
    "                        depth=None,\n",
    "                        threads=4,\n",
    "                        verbose=10,\n",
    "                        local_root=f\"/media/bekah/BekahA/eclipses\",\n",
    "                        recreate=False,\n",
    "                        aperture_sizes=[12.8],\n",
    "                        write={\"movie\": False, \"image\": True},\n",
    "                        compression=\"rice\",\n",
    "                        lil=True)\n",
    "            except: \n",
    "                print(\"no work :( \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41581bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_eclipses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b0f497",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_list = eclipse_nums[0::10]\n",
    "len(short_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at offset between sources for a single eclipse \n",
    "# use dbscan to group points based on distance \n",
    "\n",
    "eclipse = 23154\n",
    "\n",
    "def get_selected_sources(eclipse):\n",
    "    \"\"\" get central sources from both fuv and nuv for the same eclipse. returns concat\n",
    "    pd df with sources from both bands. \"\"\"\n",
    "    \n",
    "    list_folder_path = \"/media/bekah/BekahA/eclipses/\"\n",
    "    eclipse_folder_path = \"/media/bekah/BekahA/eclipses/e\"+str(eclipse)+\"/\"\n",
    "    nuv_list_name = f\"e{eclipse}, FUV, sources_pts.csv\"\n",
    "    fuv_list_name = f\"e{eclipse}, NUV, sources_pts.csv\"\n",
    "    nuv_image_name = f\"e{eclipse}-nd-full-0-rice.fits\"\n",
    "    fuv_image_name = f\"e{eclipse}-fd-full-0-rice.fits\"\n",
    "\n",
    "    nuvexists, nuvpath = check_file_in_folder(list_folder_path, nuv_list_name) \n",
    "    fuvexists, fuvpath = check_file_in_folder(list_folder_path, fuv_list_name) \n",
    "\n",
    "    if nuvexists & fuvexists: \n",
    "        nuv = pd.read_csv(nuvpath)  \n",
    "        nuv['band'] = 'nuv'\n",
    "        fuv = pd.read_csv(fuvpath) \n",
    "        fuv['band'] = 'fuv'\n",
    "\n",
    "        # filter for central sources\n",
    "        selected_nuv = nuv[(nuv['xcentroid'] > 1000) & (nuv['xcentroid'] < 2000) &\n",
    "                           (nuv['ycentroid'] > 1000) & (nuv['ycentroid'] < 2000)]\n",
    "        selected_fuv = fuv[(fuv['xcentroid'] > 1000) & (fuv['xcentroid'] < 2000) &\n",
    "                           (fuv['ycentroid'] > 1000) & (fuv['ycentroid'] < 2000)]\n",
    "\n",
    "        fuvandnuv = pd.concat([selected_nuv, selected_fuv])\n",
    "\n",
    "        return fuvandnuv \n",
    "\n",
    "    # grouping \n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def dbscan_group(fuvandnuv): \n",
    "    fuvandnuv_xy = list(zip(fuvandnuv['xcentroid'],fuvandnuv['ycentroid']))\n",
    "    dbscan = DBSCAN(eps=10, min_samples=2)\n",
    "    labels = dbscan.fit_predict(fuvandnuv_xy)\n",
    "    points_with_labels = zip(fuvandnuv_xy, labels)\n",
    "    \n",
    "    labelsdf = pd.DataFrame(points_with_labels, columns=['Point', 'Label'])\n",
    "    labelsdf[['X', 'Y']] = labelsdf['Point'].apply(lambda x: pd.Series({'X': x[0], 'Y': x[1]}))\n",
    "    labelsdf = labelsdf.drop('Point', axis=1)\n",
    "    return labelsdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d145d03f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot dbscan groups \n",
    "labeled_points = dbscan_group(fuvandnuv)\n",
    "%matplotlib notebook\n",
    "plt.scatter(labeled_points['X'],labeled_points['Y'],c=labeled_points['Label'])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot star locations for fuv and nuv \n",
    "plt.scatter(selected_fuv['xcentroid'],selected_fuv['ycentroid'])\n",
    "plt.scatter(selected_nuv['xcentroid'],selected_nuv['ycentroid'],c='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using the segmentation images, which should be more accurate than just centroids\n",
    "\n",
    "eclipse_folder_path = \"/media/bekah/BekahA/eclipses/e\"+str(eclipse)+\"/\"\n",
    "nuv_seg_image = f\"e{eclipse}-nd-segmentation_leg0.jpg\"\n",
    "fuv_seg_image = f\"e{eclipse}-fd-segmentation_leg0.jpg\"\n",
    "\n",
    "nuvexists, nuvpath = check_file_in_folder(eclipse_folder_path, nuv_seg_image) \n",
    "fuvexists, fuvpath = check_file_in_folder(eclipse_folder_path, fuv_seg_image) \n",
    "\n",
    "plt.imshow(nuvpath)\n",
    "\n",
    "#RESULT: seg images are dtype <U67  and therefore mb not high quality enough for this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50156af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using star locations + radius to draw shapes akin to seg map?\n",
    "# for every point in fuv, find it's closest match in nuv?\n",
    "\n",
    "sources = get_selected_sources(eclipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06223b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuv_dx = \"/home/bekah/glcat/fuv_offset/fuv_dx_fdttdc_coef_0.tbl.txt\"\n",
    "fuv_dy = \"/home/bekah/glcat/fuv_offset/fuv_dy_fdttdc_coef_0.tbl.txt\"\n",
    "\n",
    "fuv_dx_df = pd.read_csv(fuv_dx, delim_whitespace=True, skiprows=0)\n",
    "fuv_dy_df = pd.read_csv(fuv_dy, delim_whitespace=True, skiprows=0)\n",
    "fuv_dx_df = fuv_dx_df.drop(columns=['coef_0', '|.2','|.1'])\n",
    "fuv_dx_df = fuv_dx_df.rename(columns={\"|\": \"ecl\", \"ecl\": \"coef_0\"})\n",
    "fuv_dy_df = fuv_dy_df.drop(columns=['coef_0', '|.2','|.1'])\n",
    "fuv_dy_df = fuv_dy_df.rename(columns={\"|\": \"ecl\", \"ecl\": \"coef_0\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad2e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.scatter(fuv_dy_df['ecl'],fuv_dy_df['coef_0'])\n",
    "plt.xlabel('eclipse')\n",
    "plt.ylabel('fuv dy coef 0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fd30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "ax1.scatter(fuv_dx_df['ecl'],fuv_dx_df['coef_0'], color='blue', label='dx coef 0')\n",
    "ax1.set_ylabel('fuv dx coef 0')\n",
    "\n",
    "ax2.scatter(fuv_dx_df['ecl'],fuv_dy_df['coef_0'], color='orange', label='dy coef 0')\n",
    "ax2.set_xlabel('eclipse')\n",
    "ax2.set_ylabel('fuv dy coef 0')\n",
    "\n",
    "ax1.legend()\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e64558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    " \n",
    "    \n",
    "# DY CHANGE POINTS \n",
    "\n",
    "# slopes between consecutive points\n",
    "slopes = np.diff(fuv_dy_df['coef_0']) / np.diff(fuv_dy_df['ecl'])\n",
    "\n",
    "dy_change_points = np.where(np.diff(np.sign(slopes)))[0] + 1\n",
    "\n",
    "plt.scatter(fuv_dy_df['ecl'], fuv_dy_df['coef_0'])\n",
    "\n",
    "# highlight points where slope changes\n",
    "plt.scatter(fuv_dy_df['ecl'][dy_change_points], fuv_dy_df['coef_0'][dy_change_points], color='red', label='dy Slope Change Points')\n",
    "\n",
    "plt.xlabel('eclipse')\n",
    "plt.ylabel('fuv dy coef 0')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e220a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#DX CHANGE POINTS \n",
    "\n",
    "# slopes between consecutive points\n",
    "slopes = np.diff(fuv_dx_df['coef_0']) / np.diff(fuv_dx_df['ecl'])\n",
    "\n",
    "dx_change_points = np.where(np.diff(np.sign(slopes)))[0] + 1\n",
    "\n",
    "plt.scatter(fuv_dx_df['ecl'], fuv_dx_df['coef_0'])\n",
    "\n",
    "# highlight points where slope changes\n",
    "plt.scatter(fuv_dx_df['ecl'][dx_change_points], fuv_dx_df['coef_0'][dx_change_points], color='red', label='dx Slope Change Points')\n",
    "\n",
    "plt.xlabel('eclipse')\n",
    "plt.ylabel('fuv dx coef 0')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"dx change points: {len(dx_change_points)}\")\n",
    "print(f\"dy change points: {len(dy_change_points)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74975df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(fuv_dx_df['ecl'],fuv_dx_df['coef_0'],s=.5, label= 'dx coef 0')\n",
    "ax.scatter(fuv_dy_df['ecl'],fuv_dy_df['coef_0'],c='red',s=.5,label= 'dy coef 0')\n",
    "plt.xlabel('eclipse')\n",
    "plt.ylabel('coef 0')\n",
    "\n",
    "for line_x in dx_change_points:\n",
    "    plt.axvline(x=line_x, color='lightblue', linestyle='--',lw=.5, label=line_x)\n",
    "    \n",
    "for line_x in dy_change_points:\n",
    "    plt.axvline(x=line_x, color='lightcoral', linestyle='--',lw=.5, label=line_x)\n",
    "    \n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left', ncol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79613ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_change_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ca6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_points_df = pd.DataFrame()\n",
    "for eclipse in dx_change_points: \n",
    "    metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','==',eclipse)]).to_pandas()\n",
    "    dx_points_df = pd.concat([dx_points_df, metadata], ignore_index=True)\n",
    "    metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','==',eclipse+1)]).to_pandas()\n",
    "    dx_points_df = pd.concat([dx_points_df, metadata], ignore_index=True)\n",
    "    metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','==',eclipse+2)]).to_pandas()\n",
    "    dx_points_df = pd.concat([dx_points_df, metadata], ignore_index=True)\n",
    "    metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','==',eclipse-1)]).to_pandas()\n",
    "    dx_points_df = pd.concat([dx_points_df, metadata], ignore_index=True)\n",
    "    metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','==',eclipse-2)]).to_pandas()\n",
    "    dx_points_df = pd.concat([dx_points_df, metadata], ignore_index=True)\n",
    "\n",
    "dx_points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27101bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    display(dx_points_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dx_points_df['ra_max'],dx_points_df['dec_max'],c=dx_points_df['eclipse'],s=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b07fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_points_df = pd.DataFrame()\n",
    "for eclipse in dy_change_points: \n",
    "    metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','==',eclipse)]).to_pandas()\n",
    "    dy_points_df = pd.concat([dy_points_df, metadata], ignore_index=True)\n",
    "    metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','==',eclipse+1)]).to_pandas()\n",
    "    dy_points_df = pd.concat([dy_points_df, metadata], ignore_index=True)\n",
    "    metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','==',eclipse+2)]).to_pandas()\n",
    "    dy_points_df = pd.concat([dy_points_df, metadata], ignore_index=True)\n",
    "    metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','==',eclipse-1)]).to_pandas()\n",
    "    dy_points_df = pd.concat([dy_points_df, metadata], ignore_index=True)\n",
    "    metadata = parquet.read_table('/home/bekah/gPhoton2/gPhoton/aspect/metadata.parquet',\n",
    "                                  filters=[('eclipse','==',eclipse-2)]).to_pandas()\n",
    "    dy_points_df = pd.concat([dy_points_df, metadata], ignore_index=True)\n",
    "\n",
    "\n",
    "color_mapping = {'DIS': 'red', 'AIS': 'blue', 'MIS': 'lightblue', 'GII': 'orange', 'CAI': 'hotpink', \n",
    "                'unknown': 'cadetblue'}\n",
    "\n",
    "dy_points_df['Color'] = dy_points_df['obstype'].map(color_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dy_points_df['eclipse'],dy_points_df['fuv_temp'],c=dy_points_df[\"Color\"])\n",
    "plt.xlabel('eclipse')\n",
    "plt.ylabel('fuv_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fcb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting eclipses in ra, dec space with eclipse number \n",
    "plt.scatter(dy_points_df['ra_max'],dy_points_df['dec_max'],c=dy_points_df[\"eclipse\"], s=5)\n",
    "for i in range(len(dy_points_df)):\n",
    "    plt.text(dy_points_df['ra_max'].iloc[i], \n",
    "             dy_points_df['dec_max'].iloc[i], \n",
    "             dy_points_df['eclipse'].iloc[i],\n",
    "             va='bottom', ha='center',\n",
    "            fontsize=6)\n",
    "plt.xlabel('ra')\n",
    "plt.ylabel('dec')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_differences = [second - first for first, second in zip(dx_change_points, dx_change_points[1:])]\n",
    "dy_differences = [second - first for first, second in zip(dy_change_points, dy_change_points[1:])]\n",
    "dy_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gPhoton.io._query.mast_query import retrieve_aspect\n",
    "from gPhoton.io.mast import get_raw_paths\n",
    "\n",
    "get_raw_paths(19261)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46782f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scst_hdu = fits.open(\"/home/bekah/glcat/fuv_offset/e19261-scst.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc897e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdttdc = scst_hdu[1].data['FDTTDC'].byteswap().newbyteorder() \n",
    "pktime = scst_hdu[1].data['pktime'].byteswap().newbyteorder() \n",
    "hvnom_fuv = scst_hdu[1].data['hvnom_fuv'].byteswap().newbyteorder() \n",
    "t_dead_fuv = scst_hdu[1].data['t_dead_fuv'].byteswap().newbyteorder() \n",
    "fdtdet = scst_hdu[1].data['FDTDET'].byteswap().newbyteorder() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bd76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scst_df = pd.DataFrame({'pktime': pktime, 'fdttdc': fdttdc,\n",
    "                        'hvnom_fuv': hvnom_fuv, 't_dead_fuv': t_dead_fuv,\n",
    "                       'fdtdet': fdtdet})\n",
    "\n",
    "#trange= ( 849542598.995 , 849544054.995 )           \n",
    "min_time = float(849542598.995)\n",
    "max_time = float(849544054.995)\n",
    "subset_scst_df = scst_df[(scst_df['pktime'] >= min_time) & (scst_df['pktime'] <= max_time)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_scst = pd.read_csv(\"/home/bekah/glcat/fuv_offset/subset_scst_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2eef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "plt.scatter(subset_scst['pktime'],subset_scst['fdttdc'])\n",
    "plt.xlabel('pktime')\n",
    "plt.ylabel(\"FDTTDC\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79b4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(subset_scst['fdttdc'])\n",
    "plt.xlabel(\"fdttdc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(subset_scst_df['pktime'],subset_scst_df['fdttdc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d04b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(hvnom_fuv, fdttdc)\n",
    "plt.xlabel('hvnom_fuv')\n",
    "plt.ylabel(\"FDTTDC\")\n",
    "plt.title(\"eclipse 19261 scst file data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a816b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the slope change across eclipse time if all fdttdc data were used \n",
    "\n",
    "result = -0.07478216490196762 # in gPhoton2 \n",
    "# from lookup table:     \n",
    "fody_coef_0 = -0.03934\n",
    "fody_coef_1 = 0.3597\n",
    "fuv_temp = 29.0985325685348\n",
    "\n",
    "# gPhoton2 check \n",
    "yoffset = fody_coef_0 - (fody_coef_1 * (fuv_temp - 29.0))\n",
    "\n",
    "print(yoffset)\n",
    "print(f\"diff: {yoffset-result}\")\n",
    "\n",
    "# ok great so I can recreate what gPhoton2 does \n",
    "# gPhoton2 uses -0.07478216490196762 as the dy correction for all of 19261 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yoffset_col = fody_coef_0 - (fody_coef_1 * (subset_scst['fdttdc'] - 29.0))\n",
    "yoffset_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce139c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(yoffset_col)\n",
    "plt.axvline(x=yoffset, color='red', linestyle='--',lw=1, label=\"gPhoton2 y offset\")\n",
    "plt.xlabel(\"ecl 19261: y offset with variable fdttdc (arcseconds)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7eb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok let's do all of the above again for eclipse 3801 \n",
    "from gPhoton.io.mast import get_raw_paths\n",
    "\n",
    "paths = get_raw_paths(3801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04090172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gPhoton2 on eclipse\n",
    "execute_pipeline(\n",
    "                3801,\n",
    "                \"FUV\",\n",
    "                depth=None,\n",
    "                threads=4,\n",
    "                verbose=10,\n",
    "                local_root=f\"/media/bekah/BekahA/eclipses\",\n",
    "                recreate=False,\n",
    "                aperture_sizes=[12.8],\n",
    "                write={\"movie\": False, \"image\": True},\n",
    "                compression=\"rice\",\n",
    "                lil=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a6cd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the slope change across eclipse time if all fdttdc data were used \n",
    "\n",
    "result = -0.4705166976569246 # in gPhoton2 \n",
    "# from lookup table:     \n",
    "fody_coef_0 = -0.25999\n",
    "fody_coef_1 = 0.3597\n",
    "fuv_temp = 29.5852841191463\n",
    "\n",
    "# gPhoton2 check \n",
    "yoffset = fody_coef_0 - (fody_coef_1 * (fuv_temp - 29.0))\n",
    "\n",
    "print(yoffset)\n",
    "print(f\"diff: {yoffset-result}\")\n",
    "\n",
    "# ok great so I can recreate what gPhoton2 does \n",
    "# gPhoton2 uses -0.07478216490196762 as the dy correction for all of 19261 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df \n",
    "scst_path = \"/home/bekah/glcat/fuv_offset/e03801-scst.fits\"\n",
    "eclipse = 3801\n",
    "# trange= ( 758062104.995 , 758063802.995 )                   \n",
    "min_time = float(758062104.995)\n",
    "max_time = float(758063802.995 ) \n",
    "save_csv = f\"/home/bekah/glcat/fuv_offset/subset_scst_{eclipse}.csv\"\n",
    "\n",
    "scst_hdu = fits.open(scst_path)\n",
    "\n",
    "fdttdc = scst_hdu[1].data['FDTTDC'].byteswap().newbyteorder() \n",
    "pktime = scst_hdu[1].data['pktime'].byteswap().newbyteorder() \n",
    "hvnom_fuv = scst_hdu[1].data['hvnom_fuv'].byteswap().newbyteorder() \n",
    "t_dead_fuv = scst_hdu[1].data['t_dead_fuv'].byteswap().newbyteorder() \n",
    "fdtdet = scst_hdu[1].data['FDTDET'].byteswap().newbyteorder() \n",
    "\n",
    "scst_df = pd.DataFrame({'pktime': pktime, 'fdttdc': fdttdc,\n",
    "                        'hvnom_fuv': hvnom_fuv, 't_dead_fuv': t_dead_fuv,\n",
    "                       'fdtdet': fdtdet})\n",
    "\n",
    "\n",
    "subset_scst_df = scst_df[(scst_df['pktime'] >= min_time) & (scst_df['pktime'] <= max_time)]\n",
    "\n",
    "subset_scst_df.to_csv(save_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f63006",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_scst = pd.read_csv(\"/home/bekah/glcat/fuv_offset/subset_scst_3801.csv\")\n",
    "yoffset_col_3801 = fody_coef_0 - (fody_coef_1 * (subset_scst['fdttdc'] - 29.0))\n",
    "yoffset_col_3801\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aaa311",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yoffset_col_3801)\n",
    "plt.axvline(x=yoffset, color='red', linestyle='--',lw=1, label=\"gPhoton2 y offset\")\n",
    "plt.xlabel(\"ecl 3801: y offset with variable fdttdc (arcseconds)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccacff1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
