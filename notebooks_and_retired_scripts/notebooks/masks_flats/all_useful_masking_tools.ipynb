{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a9cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import median_filter\n",
    "import matplotlib.image\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/bekah/gPhoton2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc173f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 'f'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fdc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP ONE\n",
    "# stack backplane stacks to get an \"all dose\" image \n",
    "\n",
    "def stack_fits_images(file_list, output_path):\n",
    "    stacked_image_data = None\n",
    "    for i, file_path in enumerate(file_list):\n",
    "        with fits.open(file_path) as hdul:\n",
    "            image_data = hdul[0].data\n",
    "            if stacked_image_data is None:\n",
    "                stacked_image_data = np.zeros_like(image_data, dtype=np.float64)\n",
    "            stacked_image_data += image_data\n",
    "    hdu = fits.PrimaryHDU(stacked_image_data)\n",
    "    hdul = fits.HDUList([hdu])\n",
    "    hdul.writeto(output_path, overwrite=True)\n",
    "    print(f\"Summed image saved to {output_path}\")\n",
    "\n",
    "# get file list \n",
    "\n",
    "directory = f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks'\n",
    "\n",
    "file_list = [f for f in os.listdir(directory) if f.endswith(('.fits'))]\n",
    "file_paths = [os.path.join(directory, file_name) for file_name in file_list]\n",
    "\n",
    "output_path = f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks/all_{b}uv_summed_image.fits'\n",
    "stack_fits_images(file_paths, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3c6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP TWO\n",
    "# dividing stacked image data by the same data with a median filter to produce \"filtered\" image data\n",
    "fts2 = fits.open(f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks/all_{b}uv_summed_image.fits')\n",
    "\n",
    "image = fts2[0].data\n",
    "\n",
    "filtered_image = median_filter(image, size=10)\n",
    "filtered = np.ma.divide(image, filtered_image).filled(0)  # Filled with 0 where b is zero\n",
    "#mask = (image <= 10) | (filtered_image > median*20)\n",
    "#binary_array = mask.astype(np.uint8)\n",
    "hdu = fits.PrimaryHDU(filtered)\n",
    "hdul = fits.HDUList([hdu])\n",
    "hdul.writeto(f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks/filtered_10_{b}.fits', overwrite=True)\n",
    "print(f\"image saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b3d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP THREE\n",
    "# masking the normalized images created above in \"filtered\"\n",
    "\n",
    "fts2 = fits.open(f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks/filtered_10_{b}.fits')\n",
    "image = fts2[0].data\n",
    "mask = (image <= .75) | (image > 1.75)\n",
    "binary_array = mask.astype(np.uint8)\n",
    "hdu = fits.PrimaryHDU(binary_array)\n",
    "hdul = fits.HDUList([hdu])\n",
    "hdul.writeto(f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks/filtered_10_mask_n.fits', overwrite=True)\n",
    "print(f\"image saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120841dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP FOUR \n",
    "# add buffer to mask image \n",
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "\n",
    "with fits.open(f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks/derivatives/filtered_10_mask_{b}.fits') as hdul:\n",
    "    binary_mask = hdul[0].data\n",
    "\n",
    "buffer_size = 8\n",
    "structuring_element = np.ones((2*buffer_size+1, 2*buffer_size+1))\n",
    "\n",
    "dilated_mask = binary_dilation(binary_mask, structure=structuring_element)\n",
    "hdu = fits.PrimaryHDU(1-dilated_mask.astype(np.uint8))  \n",
    "hdul_new = fits.HDUList([hdu])\n",
    "hdul_new.writeto(f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks/derivatives/dilated_mask_filtered10_{b}.fits', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4974f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop downscaled image from the center and save\n",
    "\n",
    "def crop_center(data, cropx, cropy):\n",
    "    y, x = data.shape\n",
    "    startx = x // 2 - (cropx // 2)\n",
    "    starty = y // 2 - (cropy // 2)\n",
    "    return data[starty:starty + cropy, startx:startx + cropx]\n",
    "\n",
    "def crop_fits(old_file, new_file):\n",
    "    \n",
    "    hdul = fits.open(old_file)\n",
    "    data = hdul[0].data\n",
    "\n",
    "    cropx, cropy = 100, 100 # how much to crop in either direction\n",
    "\n",
    "    cropped_data = crop_center(data, cropx, cropy)\n",
    "\n",
    "\n",
    "    hdul[0].data = cropped_data\n",
    "\n",
    "    hdul.writeto(new_file, overwrite=True)\n",
    "\n",
    "    hdul.close()\n",
    "    \n",
    "    return cropped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573816a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downscale image \n",
    "from scipy.ndimage import zoom\n",
    "def downscale_fits_image(input_path, output_path, scale_factor=1/5.25):\n",
    "    with fits.open(input_path) as hdul:\n",
    "        image_data = hdul[0].data\n",
    "        crop_amount = 300\n",
    "        cropped_array = image_data[crop_amount:-crop_amount, crop_amount:-crop_amount]\n",
    "        \n",
    "        downscaled_image_data = zoom(cropped_array, zoom=scale_factor, order=0)\n",
    "        \n",
    "        # flip array\n",
    "        downscaled_image_data == np.rot90(np.fliplr(downscaled_image_data))\n",
    "\n",
    "        hdu = fits.PrimaryHDU(downscaled_image_data)\n",
    "        hdul_new = fits.HDUList([hdu])\n",
    "        hdul_new.writeto(output_path, overwrite=True)\n",
    "    return downscaled_image_data\n",
    "input_path = f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks/derivatives/dilated_mask_filtered10_{b}.fits'\n",
    "output_path = f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks/derivatives/dilated_mask_filtered10_downsize_{b}.fits'\n",
    "downscaled_image_data = downscale_fits_image(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add inverse of circle border around edge for edge reflections etc \n",
    "\n",
    "def add_inverse_circle_overlay(array, radius, outside_value=2):\n",
    "    rows, cols = array.shape\n",
    "    center_row, center_col = rows // 2, cols // 2\n",
    "    y, x = np.ogrid[:rows, :cols]\n",
    "    distance_from_center = np.sqrt((x - center_col) ** 2 + (y - center_row) ** 2)\n",
    "    outside_circle_mask = distance_from_center > radius\n",
    "    array[outside_circle_mask] += outside_value\n",
    "    return array\n",
    "\n",
    "\n",
    "array_with_inverse_circle = add_inverse_circle_overlay(downscaled_image_data, 350, 2)\n",
    "\n",
    "plt.imshow(array_with_inverse_circle, cmap='gray')\n",
    "plt.title('border mask added')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard deviation image between all images in folder \n",
    "\n",
    "b = \"f\"\n",
    "splits = 2\n",
    "\n",
    "folder_path = f'/media/bekah/BekahA/hotspot/200_stack_{b}uv'\n",
    "fits_files = [f for f in os.listdir(folder_path) if f.endswith(('NF.fits'))]\n",
    "images = []\n",
    "\n",
    "files_split = np.array_split(fits_files, splits)\n",
    "\n",
    "for i in range(splits): \n",
    "    print(i)\n",
    "    if i > 0: \n",
    "            del image_stack\n",
    "            del std_deviation_image\n",
    "            del images \n",
    "            images = []\n",
    "    for fits_file in list(files_split[i]):\n",
    "        fits_path = os.path.join(folder_path, fits_file)\n",
    "        print(fits_path)\n",
    "        with fits.open(fits_path) as hdul:\n",
    "            image_data = hdul[0].data        \n",
    "            images.append(image_data/np.median(image_data))\n",
    "\n",
    "    # Convert list of images to a 3D numpy array\n",
    "    image_stack = np.stack(images, axis=-1)\n",
    "\n",
    "    # Calculate the standard deviation along the last axis (stack axis)\n",
    "    std_deviation_image = np.std(image_stack, axis=-1)\n",
    "\n",
    "    # Save the standard deviation image as a new FITS file\n",
    "    hdu = fits.PrimaryHDU(std_deviation_image)\n",
    "    hdul = fits.HDUList([hdu])\n",
    "    hdul.writeto(f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/standard_deviation_image_{i}.fits', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = \"n\"\n",
    "\n",
    "folder_path = f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks'\n",
    "fits_files = [f for f in os.listdir(folder_path) if f.endswith(('.fits'))]\n",
    "images = []\n",
    "\n",
    "for fits_file in fits_files:\n",
    "        fits_path = os.path.join(folder_path, fits_file)\n",
    "        print(fits_path)\n",
    "        with fits.open(fits_path) as hdul:\n",
    "            image_data = hdul[0].data        \n",
    "            images.append(image_data/np.median(image_data))\n",
    "\n",
    "            image_stack = np.stack(images, axis=-1)\n",
    "\n",
    "std_deviation_image = np.std(image_stack, axis=-1)\n",
    "\n",
    "hdu = fits.PrimaryHDU(std_deviation_image)\n",
    "hdul = fits.HDUList([hdu])\n",
    "hdul.writeto(f'/media/bekah/BekahA/hotspot/200_stack_{b}uv/correct_stacks/derivatives/std_image_all_n.fits', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda62a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = fits.open(\"/media/bekah/BekahA/hotspot/200_stack_fuv/dilated_mask_filtered10.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ffabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7674039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de03d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "4800 x 4800 size \n",
    "goes to 600 x 600 rn \n",
    "\n",
    "it needs to be 800 x 800 but the current boundaries are too wide "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_amount = 300\n",
    "cropped_array = mask[0].data[crop_amount:-crop_amount, crop_amount:-crop_amount]\n",
    "plt.imshow(cropped_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a3bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d03721",
   "metadata": {},
   "outputs": [],
   "source": [
    "4200/800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d909c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.io import fits\n",
    "\n",
    "# Load the FITS file\n",
    "file_path = '/home/bekah/gPhoton2/gPhoton/cal_data/FUV_wiggle_y.fits'\n",
    "hdul = fits.open(file_path)\n",
    "data = hdul[0].data\n",
    "\n",
    "# Check for -0 and 0 in the data\n",
    "# Note: In floating point, -0 and 0 are distinct but often displayed the same\n",
    "# We can use the np.signbit function to find -0 specifically\n",
    "\n",
    "negative_zero_mask = np.signbit(data) & (data == 0)\n",
    "positive_zero_mask = ~np.signbit(data) & (data == 0)\n",
    "\n",
    "# Create an image to visualize the differences\n",
    "# For example, we can assign different colors to -0 and 0\n",
    "image = np.zeros((data.shape[0], data.shape[1], 3))\n",
    "\n",
    "# Assign colors: red for -0, green for +0\n",
    "image[negative_zero_mask] = [0, 0, 24] # Red for -0\n",
    "image[positive_zero_mask] = [155, 155, 0]  # Green for 0\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image, cmap='cool')\n",
    "plt.title('Difference between -0 and 0')\n",
    "plt.show()\n",
    "\n",
    "# Close the FITS file\n",
    "hdul.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d0194",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ca082",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "with fits.open('fuv_2000stack_100seceach_2.fits') as hdul:\n",
    "    data = hdul[0].data\n",
    "    \n",
    "    mask = data > 65\n",
    "    data[mask] = 40\n",
    "    median_filtered_data = median_filter(data, size=15)\n",
    "    data[mask] = median_filtered_data[mask]\n",
    "    \n",
    "    hdu = fits.PrimaryHDU(data)\n",
    "    hdul_out = fits.HDUList([hdu])\n",
    "    \n",
    "    # Save the modified data to the output FITS file\n",
    "    hdul_out.writeto('median_masked_fuvflat.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bf1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "with fits.open('fuv_2500stack_filtered1.fits') as hdul:\n",
    "    data = hdul[0].data\n",
    "\n",
    "    mask = data > 0\n",
    "    median = np.median(data[mask])\n",
    "    data = hdul[0].data / median\n",
    "    \n",
    "    hdu = fits.PrimaryHDU(data)\n",
    "    hdul_out = fits.HDUList([hdu])\n",
    "    \n",
    "    hdul_out.writeto('flat_fuv_normalized_1.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73698e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist = fits.open(\"/home/bekah/glcat/masks/drawn/fuv_combined_mask_ds_1.fits\")\n",
    "\n",
    "data = hdulist[0].data\n",
    "\n",
    "# have to transpose NUV so it matches the OG mask orientation\n",
    "fdata = np.transpose(data) # flip left-right and flip up-down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = fdata+(og*6)\n",
    "hdu = fits.PrimaryHDU(combo.astype(np.uint8))\n",
    "hdul_out = fits.HDUList([hdu])\n",
    "hdul_out.writeto('/home/bekah/glcat/masks/drawn/fuv_combo_mask.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist = fits.open(\"/media/bekah/BekahA/hotspot/200_stack_fuv/correct_stacks/derivatives/FUV_mask.fits\")\n",
    "\n",
    "og = hdulist[0].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fd297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fdata)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac70478",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fdata+og,interpolation=None)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3262e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "0-0*2 = 0 # both hotspots \n",
    "1-0*2 = 1 # old isn't a hotspot but new is \n",
    "0-1*2 = -2 # new isn't a hotspot but old is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('every3_fuv.csv')\n",
    "\n",
    "eclipse_numbers = df['eclipse'].tolist()\n",
    "\n",
    "step = len(eclipse_numbers) / 1000\n",
    "\n",
    "sampled_indices = np.arange(0, len(eclipse_numbers), step).astype(int)\n",
    "sampled_eclipse_numbers = [eclipse_numbers[i] for i in sampled_indices[:1000]]\n",
    "\n",
    "sampled_df = pd.DataFrame(sampled_eclipse_numbers, columns=['eclipse'])\n",
    "\n",
    "sampled_df.to_csv('fuv_1000e.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gPhoton.coadd import zero_flag_and_edge\n",
    "import fitsio\n",
    "\n",
    "hdulist = fitsio.FITS(\"/home/bekah/Downloads/e05697-fd-b00-ffull-image-r.fits\")\n",
    "\n",
    "cnt, flag, edge = [hdu.read() for hdu in hdulist[1:4]]\n",
    "\n",
    "masked_cnt = zero_flag_and_edge(cnt, flag, edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba611f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flag, interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854e7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = fits.open('/home/bekah/glcat/masks/drawn/fuv_combo_mask_final_b.fits')\n",
    "inverted_mask = np.abs(mask[0].data - 1)\n",
    "hdu = fits.PrimaryHDU(inverted_mask)\n",
    "hdul_out = fits.HDUList([hdu])\n",
    "hdul_out.writeto('/home/bekah/glcat/masks/drawn/inverted_final_mask_fuv.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e31e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
