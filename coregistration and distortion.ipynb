{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24d29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "from pyarrow import parquet \n",
    "import numpy as np\n",
    "import sys \n",
    "sys.path.append('/home/bekah/gPhoton2')\n",
    "from gPhoton.pipeline import execute_pipeline\n",
    "from astropy.io import fits\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8594435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_sources(eclipse, folder):\n",
    "    \"\"\" get central sources from both fuv and nuv for the same eclipse. returns concat\n",
    "    pd df with sources from both bands. \"\"\"\n",
    "    \n",
    "    nuv_list_name = f\"e{eclipse}-nd-full-0-photom-12_8.csv\"\n",
    "    fuv_list_name = f\"e{eclipse}-fd-full-0-photom-12_8.csv\"\n",
    "    nuv_image_name = f\"e{eclipse}-nd-full-0-rice.fits\"\n",
    "    fuv_image_name = f\"e{eclipse}-fd-full-0-rice.fits\"\n",
    "\n",
    "    nuvexists, nuvpath = check_file_in_folder(folder, nuv_list_name) \n",
    "    fuvexists, fuvpath = check_file_in_folder(folder, fuv_list_name) \n",
    "\n",
    "    if nuvexists & fuvexists: \n",
    "        nuv = pd.read_csv(nuvpath)  \n",
    "        nuv['band'] = 'nuv'\n",
    "        fuv = pd.read_csv(fuvpath) \n",
    "        fuv['band'] = 'fuv'\n",
    "        \n",
    "        fuvandnuv = pd.concat([nuv, fuv])\n",
    "\n",
    "        return fuvandnuv \n",
    "\n",
    "def check_file_in_folder(folder_path, file_name):\n",
    "    try:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            return True, file_path\n",
    "        else:\n",
    "            return False\n",
    "    except FileNotFoundError:\n",
    "        print(f\"The folder '{folder_path}' does not exist.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission error accessing folder '{folder_path}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "def dbscan_group(fuvandnuv): \n",
    "    from sklearn.cluster import DBSCAN\n",
    "\n",
    "    fuvandnuv_xy = list(zip(fuvandnuv['ra'],fuvandnuv['dec']))\n",
    "    dbscan = DBSCAN(eps=.001, min_samples=2)\n",
    "    labels = dbscan.fit_predict(fuvandnuv_xy)\n",
    "    points_with_labels = zip(fuvandnuv_xy, labels)\n",
    "    \n",
    "    labelsdf = pd.DataFrame(points_with_labels, columns=['Point', 'Label'])\n",
    "    labelsdf[['X', 'Y']] = labelsdf['Point'].apply(lambda x: pd.Series({'X': x[0], 'Y': x[1]}))\n",
    "    labelsdf = labelsdf.drop('Point', axis=1)\n",
    "    return labelsdf \n",
    "\n",
    "\n",
    "def calculate_vector(group):\n",
    "    group['dx'] = group['ra'].diff()\n",
    "    group['dy'] = group['dec'].diff()\n",
    "    group['size_diff'] = group['equivalent_radius'].diff()\n",
    "    return group \n",
    "\n",
    "def filter_middle_50_percent(group):\n",
    "    lower_bound_r = group['ra'].quantile(0.25)\n",
    "    upper_bound_r = group['ra'].quantile(0.75)\n",
    "    lower_bound_d = group['dec'].quantile(0.25)\n",
    "    upper_bound_d = group['dec'].quantile(0.75)\n",
    "    filtered = group[(group['ra'] >= lower_bound_r) & (group['ra'] <= upper_bound_r)\n",
    "                    & (group['dec'] >= lower_bound_d) & (group['dec'] <= upper_bound_d)]\n",
    "\n",
    "    return filtered\n",
    "\n",
    "def compare_bands(eclipse, eclipse_folder_path):\n",
    "\n",
    "    e23330 = get_selected_sources(eclipse, eclipse_folder_path)\n",
    "\n",
    "    color_mapping = {'nuv': 'red', 'fuv': 'blue'}\n",
    "\n",
    "    e23330['Color'] = e23330['band'].map(color_mapping)\n",
    "\n",
    "    # filter to middle of eclipse, change this \n",
    "    #selected_e23330 = e23330[(e23330['dec'] > -13.4) & (e23330['dec'] < -13.2) &\n",
    "    #                           (e23330['ra'] > 354.2) & (e23330['ra'] < 354.4)]\n",
    "    \n",
    "    # Apply the function to each column\n",
    "    \n",
    "    #selected_e23330 = e23330.apply(filter_middle_30_percent)\n",
    "\n",
    "    selected_e23330 = filter_middle_50_percent(e23330)\n",
    "\n",
    "    label_e23330 = dbscan_group(selected_e23330)\n",
    "    \n",
    "    e23330_matches = label_e23330[(label_e23330['Label'] > 1)]\n",
    "    \n",
    "    label_e23330 = label_e23330.rename(columns={\"X\": \"ra\", \"Y\": \"dec\"})\n",
    "\n",
    "    merged = pd.merge(selected_e23330, label_e23330, on=['ra', 'dec'], how='inner', validate=\"one_to_one\")\n",
    "    \n",
    "    merged = merged[(merged['Label'] > 1)]\n",
    "    \n",
    "    label_groups = merged.sort_values(by=['Label'])\n",
    "    \n",
    "    return label_groups "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ce12a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "eclipse = '02506'\n",
    "\n",
    "# Find corresponding points \n",
    "df = compare_bands(eclipse, f'/media/bekah/BekahA/eclipses_no_correction/e{eclipse}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15a35edd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fuv_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mband\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuv\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      2\u001b[0m nuv_df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mband\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnuv\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_point_pairs_from_df\u001b[39m(df):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Extract columns as NumPy arrays\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "fuv_df = df[df[\"band\"] == \"fuv\"]\n",
    "nuv_df = df[df[\"band\"] == \"nuv\"]\n",
    "\n",
    "\n",
    "def create_point_pairs_from_df(df):\n",
    "    # Extract columns as NumPy arrays\n",
    "    ra = df[\"ra\"].values\n",
    "    dec = df[\"dec\"].values\n",
    "    \n",
    "    # converting to pixels? \n",
    "    ra = ra/1.5\n",
    "    dec = dec/1.5\n",
    "    \n",
    "    # Concatenate columns into a single array\n",
    "    points = np.column_stack((ra, dec))\n",
    "    \n",
    "    # Reshape array to Nx2\n",
    "    point_pairs = points.reshape(-1, 2)\n",
    "    \n",
    "    return point_pairs\n",
    "\n",
    "fuv_point_pairs = create_point_pairs_from_df(fuv_df)\n",
    "nuv_point_pairs = create_point_pairs_from_df(nuv_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a45f10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformation_model = cv2.estimateAffinePartial2D(fuv_point_pairs, nuv_point_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f86b02b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00019144e+00, -1.80264626e-05, -3.98856733e-03],\n",
       "       [ 1.80264626e-05,  1.00019144e+00, -2.12030998e-03]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformation_model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94832b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49802002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transformation to one of the images\n",
    "image = fits.open('/media/bekah/BekahA/eclipses_no_correction/e02506/e02506-fd-full-0-rice.fits')\n",
    "image1 = image[1].data\n",
    "aligned_image = cv2.warpAffine(image1, transformation_model[0], (image1.shape[1], image1.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb590847",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdu = fits.CompImageHDU(aligned_image, compression_type='RICE_1')\n",
    "\n",
    "hdu.writeto('/media/bekah/BekahA/eclipses_no_correction/e02506/warped_e02506_scaled.fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bccd2eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n"
     ]
    }
   ],
   "source": [
    "eclipses = ['02188','02313','02344','02372','02461'\n",
    "            ,'02477','02492','02506','02564','02618']\n",
    "\n",
    "\n",
    "def affine_eclipse(eclipse): \n",
    "    # Find corresponding points \n",
    "    df = compare_bands(eclipse, f'/media/bekah/BekahA/eclipses_no_correction/e{eclipse}/')\n",
    "    fuv_df = df[df[\"band\"] == \"fuv\"]\n",
    "    nuv_df = df[df[\"band\"] == \"nuv\"]\n",
    "\n",
    "    fuv_point_pairs = create_point_pairs_from_df(fuv_df)\n",
    "    nuv_point_pairs = create_point_pairs_from_df(nuv_df)\n",
    "\n",
    "    transformation_model = cv2.estimateAffinePartial2D(fuv_point_pairs, nuv_point_pairs)\n",
    "\n",
    "    # apply the transformation to one of the images\n",
    "    image = fits.open(f'/media/bekah/BekahA/eclipses_no_correction/e{eclipse}/e{eclipse}-fd-full-0-rice.fits')\n",
    "    image1 = image[1].data\n",
    "    aligned_image = cv2.warpAffine(image1, transformation_model[0], (image1.shape[1], image1.shape[0]))\n",
    "\n",
    "    # write image \n",
    "    hdu = fits.CompImageHDU(aligned_image, compression_type='RICE_1')\n",
    "    hdu.writeto(f'/media/bekah/BekahA/eclipses_no_correction/e{eclipse}/warped_e{eclipse}_affine.fits', overwrite=True)\n",
    "\n",
    "    return transformation_model[0]\n",
    "\n",
    "\n",
    "for eclipse in eclipses: \n",
    "    try: \n",
    "        affine_eclipse(eclipse)\n",
    "    except:\n",
    "        print(\"something went wrong\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d150424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n"
     ]
    }
   ],
   "source": [
    "#eclipses = ['02188','02313','02344','02372','02461'\n",
    "#            ,'02477','02492','02506','02564','02618']\n",
    "\n",
    "\n",
    "eclipses = ['00922','01910','02117','02188','02344','02372',\n",
    "            '02477','02492','02506','23054','23062','23068',\n",
    "           '23085','23154','23258','23328','23330','23331',\n",
    "           '23334','23335','23336','23340']\n",
    "\n",
    "def scikit_affine_eclipse(eclipse): \n",
    "    # Find corresponding points \n",
    "    from skimage.transform import PiecewiseAffineTransform, warp\n",
    "\n",
    "    df = compare_bands(eclipse, f'/media/bekah/BekahA/eclipses_no_correction/e{eclipse}/')\n",
    "    fuv_df = df[df[\"band\"] == \"fuv\"]\n",
    "    nuv_df = df[df[\"band\"] == \"nuv\"]\n",
    "\n",
    "    fuv_point_pairs = create_point_pairs_from_df(fuv_df)\n",
    "    nuv_point_pairs = create_point_pairs_from_df(nuv_df)\n",
    "\n",
    "    print(len(nuv_point_pairs))\n",
    "    tform = PiecewiseAffineTransform()\n",
    "    tform.estimate(fuv_point_pairs, nuv_point_pairs)    \n",
    "    \n",
    "    # apply the transformation to one of the images\n",
    "    image = fits.open(f'/media/bekah/BekahA/eclipses_no_correction/e{eclipse}/e{eclipse}-fd-full-0-rice.fits')\n",
    "    image1 = image[1].data\n",
    "    aligned_image = warp(image1, tform, output_shape=(image1.shape[1], image1.shape[0]))\n",
    "\n",
    "    # write image \n",
    "    hdu = fits.CompImageHDU(aligned_image, compression_type='RICE_1')\n",
    "    hdu.writeto(f'/media/bekah/BekahA/eclipses_no_correction/e{eclipse}/warped_e{eclipse}_scikit_affine.fits', overwrite=True)\n",
    "    \n",
    "    print(tform)\n",
    "    return \n",
    "\n",
    "\n",
    "for eclipse in eclipses: \n",
    "    try: \n",
    "        scikit_affine_eclipse(eclipse)\n",
    "    except:\n",
    "        print(\"something went wrong\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d17291b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n",
      "something went wrong\n"
     ]
    }
   ],
   "source": [
    "eclipses = ['02188','02313','02344','02372','02461'\n",
    "            ,'02477','02492','02506','02564','02618']\n",
    "\n",
    "\n",
    "def homography_eclipse(eclipse): \n",
    "    # find points \n",
    "    df = compare_bands(eclipse, f'/media/bekah/BekahA/eclipses_no_correction/e{eclipse}/')\n",
    "    fuv_df = df[df[\"band\"] == \"fuv\"]\n",
    "    nuv_df = df[df[\"band\"] == \"nuv\"]\n",
    "\n",
    "    fuv_point_pairs = create_point_pairs_from_df(fuv_df)\n",
    "    nuv_point_pairs = create_point_pairs_from_df(nuv_df)\n",
    "\n",
    "    transformation_model = cv2.estimateAffinePartial2D(fuv_point_pairs, nuv_point_pairs)\n",
    "    homography, _ = cv2.findHomography(fuv_point_pairs, nuv_point_pairs)\n",
    "\n",
    "    # apply transformation\n",
    "    image = fits.open(f'/media/bekah/BekahA/eclipses_no_correction/e{eclipse}/e{eclipse}-fd-full-0-rice.fits')\n",
    "    image1 = image[1].data\n",
    "    height, width = image1.shape[:2]\n",
    "    aligned_image = cv2.warpPerspective(image1, homography, (width, height))\n",
    "\n",
    "    # write image \n",
    "    hdu = fits.CompImageHDU(aligned_image, compression_type='RICE_1')\n",
    "    hdu.writeto(f'/media/bekah/BekahA/eclipses_no_correction/e{eclipse}/warped_e{eclipse}_homog.fits', overwrite=True)\n",
    "\n",
    "    return transformation_model[0]\n",
    "\n",
    "\n",
    "for eclipse in eclipses: \n",
    "    try: \n",
    "        homography_eclipse(eclipse)\n",
    "    except:\n",
    "        print(\"something went wrong\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a08705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    homography, _ = cv2.findHomography(fuv_point_pairs, nuv_point_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b0923af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.03981748e+00,  7.57341480e-02, -7.97326223e-01],\n",
       "       [ 1.63853804e-03,  1.06920427e+00, -3.48736026e-01],\n",
       "       [ 1.62359036e-04,  3.44256930e-03,  1.00000000e+00]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb55dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "pixel_scale_ra = 1.5\n",
    "pixel_scale_dec = 1.5 \n",
    "\n",
    "# Sample celestial coordinates (RA, Dec) of reference point (e.g., center of the image)\n",
    "ra_center = ...\n",
    "dec_center = ...\n",
    "\n",
    "# Convert celestial coordinates of reference point to pixel coordinates\n",
    "pixel_x_center = (ra_center - ra_reference_point) / pixel_scale_ra\n",
    "pixel_y_center = (dec_center - dec_reference_point) / pixel_scale_dec\n",
    "\n",
    "# Apply the affine transformation to the reference point\n",
    "transformed_pixel_x_center = affine_celestial[0, 0] * pixel_x_center + affine_celestial[0, 1] * pixel_y_center + affine_celestial[0, 2]\n",
    "transformed_pixel_y_center = affine_celestial[1, 0] * pixel_x_center + affine_celestial[1, 1] * pixel_y_center + affine_celestial[1, 2]\n",
    "\n",
    "# Calculate the translation in pixel coordinates\n",
    "tx_pixel = transformed_pixel_x_center - pixel_x_center\n",
    "ty_pixel = transformed_pixel_y_center - pixel_y_center\n",
    "\n",
    "# Create the affine transformation matrix in pixel coordinates\n",
    "affine_pixel = np.array([[affine_celestial[0, 0], affine_celestial[0, 1], tx_pixel],\n",
    "                         [affine_celestial[1, 0], affine_celestial[1, 1], ty_pixel]])\n",
    "\n",
    "# Apply the transformation to the image using OpenCV\n",
    "# Read your image\n",
    "image = cv2.imread('your_image.jpg')\n",
    "\n",
    "# Apply the affine transformation\n",
    "transformed_image = cv2.warpAffine(image, affine_pixel, (image.shape[1], image.shape[0]))\n",
    "\n",
    "# Display the transformed image\n",
    "cv2.imshow('Transformed Image', transformed_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import data\n",
    "from skimage.registration import phase_cross_correlation\n",
    "from skimage.registration._phase_cross_correlation import _upsampled_dft\n",
    "from scipy.ndimage import fourier_shift\n",
    "\n",
    "\n",
    "image = data.camera()\n",
    "shift = (-22.4, 13.32)\n",
    "# The shift corresponds to the pixel offset relative to the reference image\n",
    "offset_image = fourier_shift(np.fft.fftn(image), shift)\n",
    "offset_image = np.fft.ifftn(offset_image)\n",
    "print(f'Known offset (y, x): {shift}')\n",
    "\n",
    "# pixel precision first\n",
    "shift, error, diffphase = phase_cross_correlation(image, offset_image)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "ax2 = plt.subplot(1, 3, 2, sharex=ax1, sharey=ax1)\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "\n",
    "ax1.imshow(image, cmap='gray')\n",
    "ax1.set_axis_off()\n",
    "ax1.set_title('Reference image')\n",
    "\n",
    "ax2.imshow(offset_image.real, cmap='gray')\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title('Offset image')\n",
    "\n",
    "# Show the output of a cross-correlation to show what the algorithm is\n",
    "# doing behind the scenes\n",
    "image_product = np.fft.fft2(image) * np.fft.fft2(offset_image).conj()\n",
    "cc_image = np.fft.fftshift(np.fft.ifft2(image_product))\n",
    "ax3.imshow(cc_image.real)\n",
    "ax3.set_axis_off()\n",
    "ax3.set_title(\"Cross-correlation\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'Detected pixel offset (y, x): {shift}')\n",
    "\n",
    "# subpixel precision\n",
    "shift, error, diffphase = phase_cross_correlation(image, offset_image,\n",
    "                                                  upsample_factor=100)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "ax2 = plt.subplot(1, 3, 2, sharex=ax1, sharey=ax1)\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "\n",
    "ax1.imshow(image, cmap='gray')\n",
    "ax1.set_axis_off()\n",
    "ax1.set_title('Reference image')\n",
    "\n",
    "ax2.imshow(offset_image.real, cmap='gray')\n",
    "ax2.set_axis_off()\n",
    "ax2.set_title('Offset image')\n",
    "\n",
    "# Calculate the upsampled DFT, again to show what the algorithm is doing\n",
    "# behind the scenes.  Constants correspond to calculated values in routine.\n",
    "# See source code for details.\n",
    "cc_image = _upsampled_dft(image_product, 150, 100, (shift*100)+75).conj()\n",
    "ax3.imshow(cc_image.real)\n",
    "ax3.set_axis_off()\n",
    "ax3.set_title(\"Supersampled XC sub-area\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f'Detected subpixel offset (y, x): {shift}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
