{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5896ae",
   "metadata": {},
   "source": [
    "### Slew Frame Stacking and Astrometry.Net Call \n",
    "\n",
    "#### Loose methodology to stack slew frames together and get a refined aspect solution: \n",
    "1. identify slew frames by comparing time stamps of aspect parquet and scst raw aspect solution (frames in scst\n",
    "    file and not aspect parquet are considered slew frames if they have the correct voltage) \n",
    "2. make 2s backplanes and .1 s backplanes made for the correct leg / eclipse / frames ID'd above \n",
    "3. filter 2s backplane image to make it just blurry enough for ASTRIDE to work \n",
    "4. run ASTRIDE streak detection on the 2s backplanes to get streaks from image (ASTRIDE uses edge detection) \n",
    "5. use streaks from ASTRIDE to get direction of movement (aka a linear best fit for streaks) \n",
    "6. stack / combine 10 or 20 (still deciding) .1s frames to make a more \"pointlike\" image \n",
    "7. use DAOstarfinder to get coordinates from stacked image and run Astrometry.net on that xylist OR run Astrometry.net on the stacked image \n",
    "8. backtrack to figure out which pixel in the stacked image is the \"center\" of the image and which timestamp\n",
    "    it correlates with \n",
    "9. edit aspect parquet with the astrometry.net solution \n",
    "10. run gphoton with edited aspect parquet \n",
    "11. run gphoton with OG aspect soln from SCST file \n",
    "12. check and compare FWHM of outputs from 10 and 11 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803bf9ca",
   "metadata": {},
   "source": [
    "### TO DO: \n",
    "- edit backplanes code to allow subsections of eclipses to have backplanes made for them instead of the whole thing\n",
    "  (saves time and memory) \n",
    "  \n",
    "- automate how the SCST file is downloaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cf8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pipeline Settings\n",
    "eclipse: just the int\n",
    "leg: not required, but only if you want to ONLY do a specific leg of an eclipse \n",
    "astrometry:if you want an XY list or image run with astrometry.net \n",
    "compare: if you want a quality check on the outputs by running gphoton and comparing with OG SCST file soln \n",
    "\"\"\"\n",
    "eclipse = \n",
    "leg = \n",
    "astrometry = \n",
    "compare = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a4391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eclipse info \n",
    "\"\"\" Get eclipse info: how many legs, length, flags, etc \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088bdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCST download \n",
    "\"\"\" Download SCST file from MAST \"\"\"\n",
    "\n",
    "# scst files \n",
    "paths = get_raw_paths(eclipse)\n",
    "paths['scst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70caab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some kind of loop to iterate the rest of the pipeline over each leg \n",
    "# add some kind of system to ignore leg-specific failures or report problems \n",
    "\n",
    "def meta_slew_pipeline(): \n",
    "    \"\"\"for iterating over multiple chunks / legs of slew frames in an eclispe \"\"\"\n",
    "    # get eclipse info \n",
    "    info = get_eclipse_info()\n",
    "    # get slew frames \n",
    "    slew_frames = get_slew_data(eclipse, band, scstpath)\n",
    "    # loop through slew stacking pipeline for multiple legs \n",
    "    for i in range(legs):\n",
    "        print(f\"Running slew stacking pipeling for leg {i}.\")\n",
    "        slew_stacking_pipeline()\n",
    "    print(\"Completed slew pipeline.\")\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ebcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slew_stacking_pipeline(): \n",
    "    \"\"\"main pipeline for processing a chunk of slew frames from an eclipse. \n",
    "     will have to be run multiple times for eclipses with multiple legs (ie AIS etc)\n",
    "     that have slew frames between legs. \"\"\"\n",
    "    \n",
    "    # generate file names \n",
    "    \n",
    "    # backplanes call \n",
    "    generate_backplanes() \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed8e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file_names(): \n",
    "    files = {'aspect1': , \n",
    "             'aspect2': , \n",
    "             'scst': , \n",
    "             'shortBackplanes': , \n",
    "             'longBackplanes': , \n",
    "             'smoothedLongBackplanes':\n",
    "             'streaks': }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6270700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slew_data(eclipse, band, scstpath):\n",
    "    \"\"\"\n",
    "    Use SCST file to get missing slew data aka timestamps not available in\n",
    "    the refined aspect soln that are in the scst file and are at HVNOM. \n",
    "    \"\"\"\n",
    "    from gPhoton.io.mast import get_raw_paths, download_data \n",
    "    #download scst \n",
    "    scst = download_data(\n",
    "        eclipse, \"scst\", band, datadir=os.path.dirname(scstpath),\n",
    "    )\n",
    "    scst_pd = pd.DataFrame(scst[1].data)\n",
    "    scst_pd = scst_pd.rename(columns={\"pktime\": \"time\"})\n",
    "    \n",
    "    # loading aspect table \n",
    "    parq  = parquet.read_table('/home/bekah/gphoton_working/gPhoton/aspect/aspect.parquet')\n",
    "    aspect = parq.to_pandas()\n",
    "    aspect = aspect[aspect[\"eclipse\"]==eclipse]\n",
    "    aspect = aspect.reset_index()\n",
    "    \n",
    "    #merge to get slew frames \n",
    "    merged_df = scst_pd.merge(aspect, how = 'left', on = ['time'])\n",
    "    slew_frames = slew_frames[slew_frames['hvnom_nuv']==1]\n",
    "\n",
    "    return slew_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual backplanes call (probably currently a subprocess command but eventually it will all be one pipeline)\n",
    "\n",
    "# to edit in backplanes file: \n",
    "# I think I can modify the t min and t max to specify for specific slew frame ranges \n",
    "# that would mean multiple separate calls to the backplanes module for a single eclipse\n",
    "# but that doesn't seem sig less efficient than running on multiple ranges within one backplanes call\n",
    "# the main difference would be loading the photonlist multiple times, I think \n",
    "# but ideally thiis is all only run once ... \n",
    "\n",
    "end_to_shared_memory(components, depth):\n",
    "    total_trange = (components['t'].min(), components['t'].max()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea554706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make two different kinds of backplanes and save them in a well-organized folder system \n",
    "\n",
    "def generate_backplanes(eclipse, leg, ): \n",
    "    \"\"\"\n",
    "    these are the current backplanes inputs: \n",
    "            make_backplanes(\n",
    "                eclipse=eclipse,\n",
    "                band=band,\n",
    "                depth=1,\n",
    "                leg=0,\n",
    "                threads=4,\n",
    "                burst=True,\n",
    "                local=\"/home/bekah/gphoton_working/test_data\",\n",
    "                kind=\"dose\",\n",
    "                radius=400,\n",
    "                write={'array': False, 'xylist': True},\n",
    "                inline=True,\n",
    "                threshold=.75,\n",
    "                star_size=2\n",
    "     \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b7d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 2s backplane frame \n",
    "\n",
    "def filter_image(files):\n",
    "    \"\"\"use gaussian filter to smooth image for better processing\"\"\"\n",
    "    from astropy.io import fits\n",
    "    from skimage import filters\n",
    "\n",
    "    dose_ais = fits.open(f\"/home/bekah/gphoton_working/test_data/e10982/e10982-nd-t0002-b01-f00{f}-g_dose.fits.gz\")\n",
    "\n",
    "    smooth = filters.gaussian(dose_ais[0].data, sigma=2)\n",
    "\n",
    "    hdu = fits.PrimaryHDU(smooth)\n",
    "    hdul = fits.HDUList([hdu])\n",
    "    hdul.writeto(f'{smoothed}.fits')\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ASTRIDE on 2s backplane (requires a special conda env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def streak_and_stack(): \n",
    "    \"\"\"looks at ASTRIDE results and uses streak length / direction to\n",
    "    stack .1s frames into a 1s image \"\"\"\n",
    "    streaks = pd.read_csv(f\"/home/bekah/glcat/smoothf{f}/streaks.csv\") \n",
    "    # calculate offsets \n",
    "    streaks['x_diff']=streaks['x_min']-streaks['x_max']\n",
    "    streaks['y_diff']=streaks['y_min']-streaks['y_max']\n",
    "    # max offset \n",
    "    ymax = max(abs(streaks['y_diff']))\n",
    "    xmax = max(abs(streaks['x_diff']))\n",
    "    ymean = np.mean(abs(streaks['y_diff']))\n",
    "    xmean = np.mean(abs(streaks['x_diff']))\n",
    "    slope = ymax / xmax\n",
    "    mean = np.mean(streaks['slope'])\n",
    "    print(f'calculated slope is {slope}, mean slope from streaks is {mean}.')\n",
    "    xrate = xmax / expt \n",
    "    yrate = ymax / expt # used to be ymax / xmax\n",
    "    # Number of pixels to offset each image.\n",
    "    x_offset, y_offset = int(xrate*.1)-5, int(yrate*.1)-5 \n",
    "    frames = int((ones_frame)/.1)\n",
    "    hdul = fits.open(f\"/home/bekah/gphoton_working/test_data/e10982/e10982-nd-t00.1-b01-f{frames}-g_dose.fits.gz\")\n",
    "    img1 = hdul[0].data\n",
    "    new_shape = ((layers - 1)*y_offset + img1.shape[0],\n",
    "                 (layers - 1)*x_offset + img1.shape[1])  \n",
    "    stacked = np.zeros(new_shape) #, dtype=np.float)\n",
    "    stacked2 = np.zeros(new_shape) #, dtype=np.float)\n",
    "    # adding image layers together \n",
    "    for layer in range(layers):\n",
    "        print(\"adding image layers together\")\n",
    "        frame = frames + layer \n",
    "        frame2 = frames + layer + layers \n",
    "        dose_ais = fits.open(f\"/home/bekah/gphoton_working/test_data/e10982/e10982-nd-t00.1-b01-f{frame}-g_dose.fits.gz\")\n",
    "        img1 = dose_ais[0].data #*layer # for tagging pixels as being from a layer  \n",
    "        layer_op = (layers-1) - layer \n",
    "        stacked[layer_op*y_offset:layer_op*y_offset + img1.shape[0],\n",
    "        layer_op*x_offset:layer_op*x_offset + img1.shape[1]] += img1\n",
    "    # saving image to fits \n",
    "    hdu = fits.PrimaryHDU(stacked)\n",
    "    hdul = fits.HDUList([hdu])\n",
    "    hdul.writeto('stacked2.fits',overwrite=True)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66d5031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXYlist_stackedFrames():\n",
    "    \"\"\"Use DAOStarFinder to extract point sources from stacked frames and \n",
    "    produce a fits XYlist. \"\"\"\n",
    "    from photutils import DAOStarFinder\n",
    "    # opening image for DAO starfinder \n",
    "    s = fits.open('/home/bekah/glcat/stacked2.fits')\n",
    "    sim = s[0].data\n",
    "    # trying dao star finder / xylist call to astrometry.net instead of \n",
    "    # using an image run \n",
    "    daofind = DAOStarFinder(fwhm=4, threshold=1, sharplo=0.00)\n",
    "    star_list = daofind(sim)\n",
    "    tbl = star_list.to_pandas()\n",
    "    star_list = tbl.sort_values(by=\"flux\", ascending=False)\n",
    "    colx = fits.Column(name='X', format='E', array=tbl['xcentroid'])\n",
    "    coly = fits.Column(name='Y', format='E', array=tbl['ycentroid'])\n",
    "    hdu = fits.BinTableHDU.from_columns([colx, coly])\n",
    "    tableName = \"starlist_slew.fits\"\n",
    "    hdu.writeto(tableName, overwrite=True)\n",
    "    print('getting image width and height')\n",
    "    h, w = sim.shape\n",
    "    print(f'height is {h} and width is {w}')\n",
    "    return h, w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82446a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run astrometry.net \n",
    "\n",
    "def astrometry_xylist_slew(h, w): \n",
    "    \n",
    "    import subprocess \n",
    "\n",
    "    cmd = f\"solve-field --overwrite -w {w} -e {h} \" \\\n",
    "          f\"--scale-units arcsecperpix --scale-low 1.0 --scale-high 1.5 \" \\\n",
    "          f\"--radius 5 '/home/bekah/glcat/starlist_slew.fits'\"\n",
    "\n",
    "    subprocess.call(cmd, shell=True)\n",
    "    \n",
    "    print(\"Astrometry.net subprocess called.\")\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924a2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out any transformations required by center of image / pixel sitn \n",
    "\n",
    "def correct_aspect(): \n",
    "    \"\"\"getting ra, dec solution for the center of the first frame \n",
    "    in the stacked series \"\"\"\n",
    "    \n",
    "    return \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec642ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_slew_to_aspect(eclipse, file_names):\n",
    "    \"\"\"adds slewframes to aspect table for eclipse so that the slew\n",
    "    frames can be added to photonlists\"\"\"\n",
    "    from pyarrow import parquet\n",
    "    from gPhoton.io.mast import get_raw_paths, download_data \n",
    "\n",
    "    # loading aspect table to add time stamp and flags\n",
    "    parq = parquet.read_table(file_names['old_aspect_parq'])\n",
    "    aspect = parq.to_pandas()\n",
    "    aspect = aspect[aspect[\"eclipse\"] == eclipse]\n",
    "    aspect = aspect.reset_index()\n",
    "\n",
    "    #download scst \n",
    "    scst = download_data(eclipse, \"scst\", band, datadir=os.path.dirname(scstpath),)\n",
    "    scst_pd = pd.DataFrame(scst[1].data)\n",
    "    scst_pd = scst_pd.rename(columns={\"pktime\": \"time\"})\n",
    "\n",
    "    #merge to get slew frames \n",
    "    merged_df = scst_pd.merge(aspect, how = 'left', on = ['time'])\n",
    "    slew_frames = slew_frames[slew_frames['hvnom_nuv']==1]\n",
    "    \n",
    "    # use acs solns for ra / dec / roll for slew frames in asp soln \n",
    "    slew_frames['ra'] = slew_frames['ra'].fillna(slew_frames['ra_acs'])\n",
    "    slew_frames['dec'] = slew_frames['dec'].fillna(slew_frames['dec_acs'])\n",
    "    slew_frames['roll'] = slew_frames['roll'].fillna(slew_frames['roll_acs'])\n",
    "    \n",
    "    slew_frames = slew_frames.astype({'ra': 'float64',\n",
    "                          'dec': 'float64',\n",
    "                          'roll': 'float64'})\n",
    "\n",
    "    # save to parquet\n",
    "    slew_frames.to_parquet(file_names[\"aspect_parq\"], compression=None)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45d8605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993f9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get slew frames \n",
    "\n",
    "# loading aspect table \n",
    "parq  = parquet.read_table('/home/bekah/gphoton_working/gPhoton/aspect/aspect.parquet')\n",
    "aspect = parq.to_pandas()\n",
    "aspect = aspect[aspect[\"eclipse\"]==eclipse]\n",
    "aspect = aspect.reset_index()\n",
    "\n",
    "# open scst file \n",
    "scst = fits.open(\"/home/bekah/gphoton_working/e10982-scst.fits.gz\")\n",
    "scst_pd = pd.DataFrame(scst[1].data)\n",
    "scst_pd = scst_pd.rename(columns={\"pktime\": \"time\"})\n",
    "\n",
    "merged_df = scst_pd.merge(aspect, how = 'left', on = ['time'])\n",
    "slew_frames = merged_df[merged_df['ra'].isna()]\n",
    "# voltage needs to be correct \n",
    "slew_frames = slew_frames[slew_frames['hvnom_nuv']==1]\n",
    "\n",
    "slew_frames['ra'] = slew_frames['ra'].fillna(slew_frames['ra_acs'])\n",
    "slew_frames['dec'] = slew_frames['dec'].fillna(slew_frames['dec_acs'])\n",
    "slew_frames['roll'] = slew_frames['roll'].fillna(slew_frames['roll_acs'])\n",
    "\n",
    "return slew_frames "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
